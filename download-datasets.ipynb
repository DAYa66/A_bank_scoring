{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке загружал тренировочные данные по 7 фолдам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:45.050970Z",
     "iopub.status.busy": "2023-03-26T13:11:45.050494Z",
     "iopub.status.idle": "2023-03-26T13:11:45.117110Z",
     "shell.execute_reply": "2023-03-26T13:11:45.115961Z",
     "shell.execute_reply.started": "2023-03-26T13:11:45.050911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/alfa-bank-train-target-folds/train_target_fold_6.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/train_target_fold_2.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/val_target_fold_3.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/train_target_fold_7.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/val_target_fold_6.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/val_target_fold_2.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/embedding_projections_dictionary .pkl\n",
      "/kaggle/input/alfa-bank-train-target-folds/val_target_fold_4.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/train_target_fold_3.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/train_target_fold_5.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/val_target_fold_7.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/train_target_fold_4.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/val_target_fold_1.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/val_target_fold_5.csv\n",
      "/kaggle/input/alfa-bank-train-target-folds/train_target_fold_1.csv\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/sample_submission.csv\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/description.xlsx\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_target.csv\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/test_target.csv\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/test_data/test_data_0.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/test_data/test_data_1.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_0.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_9.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_5.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_4.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_2.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_10.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_3.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_8.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_6.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_11.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_1.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_7.pq\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:45.119447Z",
     "iopub.status.busy": "2023-03-26T13:11:45.118860Z",
     "iopub.status.idle": "2023-03-26T13:11:56.769339Z",
     "shell.execute_reply": "2023-03-26T13:11:56.768243Z",
     "shell.execute_reply.started": "2023-03-26T13:11:45.119410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np#\n",
    "from tensorflow import keras#\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb \n",
    "from bayes_opt import BayesianOptimization\n",
    "from itertools import combinations\n",
    "\n",
    "#import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# здесь лежат функции для обработки данных\n",
    "sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:56.771318Z",
     "iopub.status.busy": "2023-03-26T13:11:56.770780Z",
     "iopub.status.idle": "2023-03-26T13:11:56.872053Z",
     "shell.execute_reply": "2023-03-26T13:11:56.870714Z",
     "shell.execute_reply.started": "2023-03-26T13:11:56.771285Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-pastel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:56.876948Z",
     "iopub.status.busy": "2023-03-26T13:11:56.876033Z",
     "iopub.status.idle": "2023-03-26T13:11:56.970506Z",
     "shell.execute_reply": "2023-03-26T13:11:56.969246Z",
     "shell.execute_reply.started": "2023-03-26T13:11:56.876898Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data\"\n",
    "TEST_DATA_PATH = \"/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/test_data\"\n",
    "\n",
    "#TRAIN_TARGET_PATH = \"/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_target.csv\"\n",
    "TRAIN_1_TARGET_PATH = \"/kaggle/input/alfa-bank-train-target-folds/train_target_fold_1.csv\"\n",
    "VAL_1_TARGET_PATH = \"/kaggle/input/alfa-bank-train-target-folds/val_target_fold_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:56.973289Z",
     "iopub.status.busy": "2023-03-26T13:11:56.972730Z",
     "iopub.status.idle": "2023-03-26T13:11:57.064475Z",
     "shell.execute_reply": "2023-03-26T13:11:57.062869Z",
     "shell.execute_reply.started": "2023-03-26T13:11:56.973247Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0, num_parts_to_read: int = 2, \n",
    "                                    columns: List[str] = None, verbose: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Читает ``num_parts_to_read`` партиций и преобразует их к pandas.DataFrame.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    path_to_dataset: str\n",
    "        Путь до директории с партициями.\n",
    "    start_from: int, default=0\n",
    "        Номер партиции, с которой начать чтение.\n",
    "    num_parts_to_read: int, default=2\n",
    "        Число партиций, которые требуется прочитать.\n",
    "    columns: List[str], default=None\n",
    "        Список колонок, которые нужно прочитать из каждой партиции. Если None, то считываются все колонки.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    frame: pandas.DataFrame\n",
    "        Прочитанные партиции, преобразованные к pandas.DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    start_from = max(0, start_from)\n",
    "    # dictionory of format {partition number: partition filename}\n",
    "    dataset_paths = {int(os.path.splitext(filename)[0].split(\"_\")[-1]): os.path.join(path_to_dataset, filename)\n",
    "                     for filename in os.listdir(path_to_dataset)}\n",
    "    chunks = [dataset_paths[num] for num in sorted(dataset_paths.keys()) if num>=start_from][:num_parts_to_read]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Reading chunks:\", *chunks, sep=\"\\n\")\n",
    "    for chunk_path in tqdm(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path, columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:57.067061Z",
     "iopub.status.busy": "2023-03-26T13:11:57.066632Z",
     "iopub.status.idle": "2023-03-26T13:11:59.290804Z",
     "shell.execute_reply": "2023-03-26T13:11:59.289696Z",
     "shell.execute_reply.started": "2023-03-26T13:11:57.067023Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "features = [\"pre_since_opened\", \"pre_since_confirmed\", \"pre_pterm\", \"pre_fterm\", \"pre_till_pclose\", \"pre_till_fclose\",\n",
    "            \"pre_loans_credit_limit\", \"pre_loans_next_pay_summ\", \"pre_loans_outstanding\", \"pre_loans_total_overdue\",\n",
    "            \"pre_loans_max_overdue_sum\", \"pre_loans_credit_cost_rate\",\n",
    "            \"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\",\n",
    "            \"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\",\n",
    "            \"pre_util\", \"pre_over2limit\", \"pre_maxover2limit\", \"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\",\n",
    "            \"enc_paym_0\", \"enc_paym_1\", \"enc_paym_2\", \"enc_paym_3\", \"enc_paym_4\", \"enc_paym_5\", \"enc_paym_6\", \"enc_paym_7\", \"enc_paym_8\",\n",
    "            \"enc_paym_9\", \"enc_paym_10\", \"enc_paym_11\", \"enc_paym_12\", \"enc_paym_13\", \"enc_paym_14\", \"enc_paym_15\", \"enc_paym_16\",\n",
    "            \"enc_paym_17\", \"enc_paym_18\", \"enc_paym_19\", \"enc_paym_20\", \"enc_paym_21\", \"enc_paym_22\", \"enc_paym_23\", \"enc_paym_24\",\n",
    "            \"enc_loans_account_holder_type\", \"enc_loans_credit_status\", \"enc_loans_credit_type\", \"enc_loans_account_cur\",\n",
    "            \"pclose_flag\", \"fclose_flag\"]\n",
    "\n",
    "\n",
    "def batches_generator(list_of_paths: List[str], batch_size: int = 32, shuffle: bool = False,\n",
    "                      is_infinite: bool = False, verbose: bool = False, device: torch.device = None,\n",
    "                      output_format: str = \"torch\", is_train: bool = True):\n",
    "    \"\"\"\n",
    "    Создает батчи на вход рекуррентных нейронных сетей, реализованных на фреймворках tensorflow и pytorch.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    list_of_paths: List[str]\n",
    "        Список путей до файлов с предобработанными последовательностями.\n",
    "    batch_size: int, default=32\n",
    "        Размер батча.\n",
    "    shuffle: bool, default=False\n",
    "        Перемешивать ли данные перед генерацией батчей.\n",
    "    is_infinite: bool, default=False\n",
    "        Должен ли генератор быть бесконечным.\n",
    "    verbose: bool, default=False\n",
    "        Печатать ли имя текущего обрабатываемого файла.\n",
    "    device: torch.device, default=None\n",
    "        Девайс, на который переместить данные при ``output_format``=\"torch\". Игнорируется, если ``output_format``=\"tf\".\n",
    "    output_format: str, default=\"torch\"\n",
    "        Формат возвращаемых данных. Допустимые значения: \"torch\", \"tf\".\n",
    "        Если \"torch\", то возвращает словарь, с ключами \"id_\", \"features\" и \"label\", если is_train=True,\n",
    "        и содержащий идентификаторы заявок, признаки и тагрет соответственно.\n",
    "        Признаки и таргет помещаются на девайс, указанный в ``device``.\n",
    "        Если \"tf\", то возращает кортеж (признаки, таргет), если ``is_train``=True, и кортеж (признаки, идентификаторы заявок) иначе.\n",
    "    is_train: bool, default=True\n",
    "        Используется ли генератор для обучения модели или для инференса.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    result: dict or tuple\n",
    "        Выходной словарь или кортеж в зависимости от параметра ``output_format``.\n",
    "    \"\"\"\n",
    "    if output_format not in [\"torch\", \"tf\"]:\n",
    "        raise ValueError(\"Unknown format. Please choose one of the following formats: \\\"torch\\\", \\\"tf\\\"\")\n",
    "\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(list_of_paths)\n",
    "\n",
    "        for path in list_of_paths:\n",
    "            if verbose:\n",
    "                print(f\"Reading {path}\")\n",
    "\n",
    "            with open(path, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "\n",
    "            ids, padded_sequences, targets = data[\"id\"], data[\"padded_sequences\"], data[\"target\"]\n",
    "            indices = np.arange(len(ids))\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "                ids = ids[indices]\n",
    "                padded_sequences = padded_sequences[indices]\n",
    "                if is_train:\n",
    "                    targets = targets[indices]\n",
    "\n",
    "            for idx in range(len(ids)):\n",
    "                bucket_ids = ids[idx]\n",
    "                bucket = padded_sequences[idx]\n",
    "                if is_train:\n",
    "                    bucket_targets = targets[idx]\n",
    "\n",
    "                for jdx in range(0, len(bucket), batch_size):\n",
    "                    batch_ids = bucket_ids[jdx: jdx + batch_size]\n",
    "                    batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "                    if is_train:\n",
    "                        batch_targets = bucket_targets[jdx: jdx + batch_size]\n",
    "\n",
    "                    if output_format == \"tf\":\n",
    "                        batch_sequences = [batch_sequences[:, i] for i in range(len(features))]\n",
    "\n",
    "                        if is_train:\n",
    "                            yield batch_sequences, batch_targets\n",
    "                        else:\n",
    "                            yield batch_sequences, batch_ids\n",
    "                    else:\n",
    "                        batch_sequences = [torch.LongTensor(batch_sequences[:, i]).to(device) for i in range(len(features))]\n",
    "                        if is_train:\n",
    "                            yield dict(id_=batch_ids,\n",
    "                                       features=batch_sequences,\n",
    "                                       label=torch.LongTensor(batch_targets).to(device))\n",
    "                        else:\n",
    "                            yield dict(id_=batch_ids,\n",
    "                                       features=batch_sequences)\n",
    "        if not is_infinite:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:59.292868Z",
     "iopub.status.busy": "2023-03-26T13:11:59.292497Z",
     "iopub.status.idle": "2023-03-26T13:11:59.387435Z",
     "shell.execute_reply": "2023-03-26T13:11:59.385299Z",
     "shell.execute_reply.started": "2023-03-26T13:11:59.292830Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def pad_sequence(array: np.ndarray, max_len: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Принимает на вход массив массивов ``array`` и производит padding каждого вложенного массива до ``max_len``.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    array: numpy.ndarray\n",
    "        Входной массив массивов.\n",
    "    max_len: int\n",
    "        Длина, до которой нужно сделать padding вложенных массивов.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    output: numpy.ndarray\n",
    "        Выходной массив.\n",
    "    \"\"\"\n",
    "    if isinstance(max_len, float):\n",
    "        print(max_len)\n",
    "    output = np.zeros((len(features), max_len))\n",
    "    output[:, :array.shape[1]] = array\n",
    "    return output\n",
    "\n",
    "\n",
    "def truncate(x, num_last_credits: int = 0):\n",
    "    return pd.Series({\"sequences\": x.values.transpose()[:, -num_last_credits:]})\n",
    "\n",
    "\n",
    "def transform_credits_to_sequences(credits_frame: pd.DataFrame,\n",
    "                                   num_last_credits: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Принимает pandas.DataFrame с записями кредитных историй клиентов, сортирует кредиты по клиентам\n",
    "    (внутри клиента сортирует кредиты от старых к новым), берет ``num_last_credits`` кредитов,\n",
    "    возвращает новый pandas.DataFrame с двумя колонками: id и sequences.\n",
    "    Каждое значение в столбце sequences - это массив массивов.\n",
    "    Каждый вложенный массив - значение одного признака во всех кредитах клиента.\n",
    "    Всего признаков len(features), поэтому будет len(features) массивов.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    credits_frame: pandas.DataFrame\n",
    "        Датафрейм с записями кредитных историй клиентов.\n",
    "    num_last_credits: int, default=0\n",
    "         Количество кредитов клиента, которые будут включены в выходные данные. Если 0, то берутся все кредиты.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    output: pandas.DataFrame\n",
    "        Выходной датафрейм с двумя столбцами: \"id\", \"sequences\".\n",
    "    \"\"\"\n",
    "    return credits_frame \\\n",
    "        .sort_values([\"id\", \"rn\"]) \\\n",
    "        .groupby([\"id\"])[features] \\\n",
    "        .apply(lambda x: truncate(x, num_last_credits=num_last_credits)) \\\n",
    "        .reset_index()\n",
    "\n",
    "\n",
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path: str = None, has_target: bool = True):\n",
    "    \"\"\"\n",
    "    Реализует Sequence Bucketing технику для обучения рекуррентных нейронных сетей.\n",
    "    Принимает на вход датафрейм ``frame_of_sequences`` с двумя столбцами: \"id\", \"sequences\"\n",
    "    (результат работы функции transform_credits_to_sequences),\n",
    "    словарь ``bucket_info``, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding, группирует кредиты по бакетам (на основе длины), производит padding нулями и сохраняет результат\n",
    "    в pickle файл, если требуется.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    frame_of_sequences: pandas.DataFrame\n",
    "        Входной датафрейм с двумя столбцами \"id\", \"sequences\" (результат работы функции transform_credits_to_sequences).\n",
    "    bucket_info: Dict[int, int]\n",
    "        Cловарь, где для последовательности каждой длины указано, до какой максимальной длины нужно делать padding.\n",
    "    save_to_file_path: str, default=None\n",
    "        Опциональный путь до файла, куда нужно сохранить результат. Если None, то сохранение не требуется.\n",
    "    has_target: bool, deafult=True\n",
    "        Флаг, есть ли в frame_of_sequences целевая переменная или нет. Если есть, то она также будет записана в выходной словарь.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    dict_result: dict\n",
    "        Выходной словарь со ключами:  \"id\", \"padded_sequences\", \"target\".\n",
    "    \"\"\"\n",
    "    frame_of_sequences[\"sequence_length\"] = frame_of_sequences[\"sequences\"].apply(lambda x: len(x[1]))\n",
    "    frame_of_sequences[\"bucket_idx\"] = frame_of_sequences[\"sequence_length\"].map(bucket_info)\n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    ids = []\n",
    "\n",
    "    for size, bucket in tqdm(frame_of_sequences.groupby(\"bucket_idx\"), desc=\"Extracting buckets\"):\n",
    "        padded_sequences = bucket[\"sequences\"].apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_seq.append(np.stack(padded_sequences, axis=0))\n",
    "\n",
    "        if has_target:\n",
    "            targets.append(bucket[\"flag\"].values)\n",
    "\n",
    "        ids.append(bucket[\"id\"].values)\n",
    "\n",
    "    frame_of_sequences.drop(columns=[\"bucket_idx\"], inplace=True)\n",
    "\n",
    "    dict_result = {\n",
    "        \"id\": np.array(ids, dtype=np.object),\n",
    "        \"padded_sequences\": np.array(padded_seq, dtype=np.object),\n",
    "        \"target\": np.array(targets, dtype=np.object) if targets else []\n",
    "    }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, \"wb\") as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Один из аргументов в функции `dataset_preprocessing_utils.create_padded_buckets` &ndash; `bucket_info` &ndash; словарь, где для конкретной длины последовательности указано до какой длины нужно делать паддинг. Для данного бэйзлайна возьмем простое разбиение на 43 бакета: \n",
    "| Длина последовательности | Длина после паддинга |\n",
    "| :-: | :-: \n",
    "| 1 &ndash; 40 | без изменений |\n",
    "| 41 &ndash; 45 | 45 |\n",
    "| 46 &ndash; 50 | 50 |\n",
    "| 51 &ndash; 58 | 58 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:59.586494Z",
     "iopub.status.busy": "2023-03-26T13:11:59.585589Z",
     "iopub.status.idle": "2023-03-26T13:11:59.674249Z",
     "shell.execute_reply": "2023-03-26T13:11:59.672550Z",
     "shell.execute_reply.started": "2023-03-26T13:11:59.586445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 11: 11,\n",
       " 12: 12,\n",
       " 13: 13,\n",
       " 14: 14,\n",
       " 15: 15,\n",
       " 16: 16,\n",
       " 17: 17,\n",
       " 18: 18,\n",
       " 19: 19,\n",
       " 20: 20,\n",
       " 21: 21,\n",
       " 22: 22,\n",
       " 23: 23,\n",
       " 24: 24,\n",
       " 25: 25,\n",
       " 26: 26,\n",
       " 27: 27,\n",
       " 28: 28,\n",
       " 29: 29,\n",
       " 30: 30,\n",
       " 31: 31,\n",
       " 32: 32,\n",
       " 33: 33,\n",
       " 34: 34,\n",
       " 35: 35,\n",
       " 36: 36,\n",
       " 37: 37,\n",
       " 38: 38,\n",
       " 39: 39,\n",
       " 40: 40,\n",
       " 41: 45,\n",
       " 42: 45,\n",
       " 43: 45,\n",
       " 44: 45,\n",
       " 45: 45,\n",
       " 46: 50,\n",
       " 47: 50,\n",
       " 48: 50,\n",
       " 49: 50,\n",
       " 50: 50,\n",
       " 51: 58,\n",
       " 52: 58,\n",
       " 53: 58,\n",
       " 54: 58,\n",
       " 55: 58,\n",
       " 56: 58,\n",
       " 57: 58,\n",
       " 58: 58}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_ = list(range(1, 59)) \n",
    "lens_ = list(range(1, 41)) + [45] * 5 + [50] * 5 + [58] * 8\n",
    "bucket_info = dict(zip(keys_, lens_))\n",
    "bucket_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Так же рассмотрим уникальные значения признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Поскольку паддинг будет производиться нулями, а категориальные признаки закодированы, начиная с 0, перед паддингом будем сдвигать все значения на 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Вся описанная выше предобработка данных реализована в виде функции `create_buckets_from_credits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:11:59.677002Z",
     "iopub.status.busy": "2023-03-26T13:11:59.676302Z",
     "iopub.status.idle": "2023-03-26T13:11:59.759180Z",
     "shell.execute_reply": "2023-03-26T13:11:59.757761Z",
     "shell.execute_reply.started": "2023-03-26T13:11:59.676964Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_buckets_from_credits(path_to_dataset, bucket_info, save_to_path, frame_with_ids = None, \n",
    "                                num_parts_to_preprocess_at_once: int = 1, \n",
    "                                num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",
    "                     desc=\"Preparing credit data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, verbose=True)\n",
    "        credits_frame.loc[:, features] += 1       \n",
    "        seq = transform_credits_to_sequences(credits_frame)\n",
    "        print(\"Transforming credits to sequences is done.\")\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on=\"id\")\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = \"00\" + block_as_str\n",
    "        else:\n",
    "            block_as_str = \"0\" + block_as_str\n",
    "            \n",
    "        processed_fragment =  create_padded_buckets(seq, bucket_info=bucket_info, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f\"processed_chunk_{block_as_str}.pkl\"))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Обучение и валидация будут происходить на семи фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:40.162247Z",
     "iopub.status.busy": "2023-03-26T13:13:40.161844Z",
     "iopub.status.idle": "2023-03-26T13:13:40.250745Z",
     "shell.execute_reply": "2023-03-26T13:13:40.249381Z",
     "shell.execute_reply.started": "2023-03-26T13:13:40.162213Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_BUCKETS_PATH_1 = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T12:44:22.547690Z",
     "iopub.status.busy": "2023-03-26T12:44:22.547347Z",
     "iopub.status.idle": "2023-03-26T12:44:24.847505Z",
     "shell.execute_reply": "2023-03-26T12:44:24.844126Z",
     "shell.execute_reply.started": "2023-03-26T12:44:22.547658Z"
    }
   },
   "source": [
    "TRAIN_BUCKETS_PATH_1 = \"/kaggle/working/train_buckets_fold_1\"\n",
    "!rm -rf $TRAIN_BUCKETS_PATH_1\n",
    "!mkdir $TRAIN_BUCKETS_PATH_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_BUCKETS_PATH_1 = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T11:49:47.575963Z",
     "iopub.status.busy": "2023-03-26T11:49:47.575325Z",
     "iopub.status.idle": "2023-03-26T11:49:49.276682Z",
     "shell.execute_reply": "2023-03-26T11:49:49.275097Z",
     "shell.execute_reply.started": "2023-03-26T11:49:47.575930Z"
    }
   },
   "source": [
    "VAL_BUCKETS_PATH_1 = \"/kaggle/working/val_buckets_fold_1\"\n",
    "!rm -rf $VAL_BUCKETS_PATH_1\n",
    "!mkdir $VAL_BUCKETS_PATH_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BUCKETS_PATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:40:42.922379Z",
     "iopub.status.busy": "2023-03-26T13:40:42.921920Z",
     "iopub.status.idle": "2023-03-26T13:40:45.362404Z",
     "shell.execute_reply": "2023-03-26T13:40:45.360673Z",
     "shell.execute_reply.started": "2023-03-26T13:40:42.922343Z"
    }
   },
   "source": [
    "TEST_BUCKETS_PATH = \"/kaggle/working/test_buckets_rnn\"\n",
    "!rm -rf $TEST_BUCKETS_PATH\n",
    "!mkdir $TEST_BUCKETS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:40.253373Z",
     "iopub.status.busy": "2023-03-26T13:13:40.253014Z",
     "iopub.status.idle": "2023-03-26T13:13:41.046481Z",
     "shell.execute_reply": "2023-03-26T13:13:41.045279Z",
     "shell.execute_reply.started": "2023-03-26T13:13:40.253338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571423</th>\n",
       "      <td>2999993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571424</th>\n",
       "      <td>2999994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571425</th>\n",
       "      <td>2999996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571426</th>\n",
       "      <td>2999997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571427</th>\n",
       "      <td>2999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571428 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  flag\n",
       "0              0     0\n",
       "1              1     0\n",
       "2              2     0\n",
       "3              4     0\n",
       "4              5     0\n",
       "...          ...   ...\n",
       "2571423  2999993     0\n",
       "2571424  2999994     0\n",
       "2571425  2999996     0\n",
       "2571426  2999997     0\n",
       "2571427  2999999     0\n",
       "\n",
       "[2571428 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/alfa-bank-train-target-folds/train_target_fold_1.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:41.048134Z",
     "iopub.status.busy": "2023-03-26T13:13:41.047764Z",
     "iopub.status.idle": "2023-03-26T13:13:42.117390Z",
     "shell.execute_reply": "2023-03-26T13:13:42.116367Z",
     "shell.execute_reply.started": "2023-03-26T13:13:41.048101Z"
    }
   },
   "outputs": [],
   "source": [
    "train.index = list(train['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:42.120197Z",
     "iopub.status.busy": "2023-03-26T13:13:42.119821Z",
     "iopub.status.idle": "2023-03-26T13:13:42.205506Z",
     "shell.execute_reply": "2023-03-26T13:13:42.204257Z",
     "shell.execute_reply.started": "2023-03-26T13:13:42.120163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999993</th>\n",
       "      <td>2999993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999994</th>\n",
       "      <td>2999994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571428 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  flag\n",
       "0              0     0\n",
       "1              1     0\n",
       "2              2     0\n",
       "4              4     0\n",
       "5              5     0\n",
       "...          ...   ...\n",
       "2999993  2999993     0\n",
       "2999994  2999994     0\n",
       "2999996  2999996     0\n",
       "2999997  2999997     0\n",
       "2999999  2999999     0\n",
       "\n",
       "[2571428 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:42.207600Z",
     "iopub.status.busy": "2023-03-26T13:13:42.207170Z",
     "iopub.status.idle": "2023-03-26T13:13:42.407169Z",
     "shell.execute_reply": "2023-03-26T13:13:42.405886Z",
     "shell.execute_reply.started": "2023-03-26T13:13:42.207556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428567</th>\n",
       "      <td>2999986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428568</th>\n",
       "      <td>2999988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428569</th>\n",
       "      <td>2999989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428570</th>\n",
       "      <td>2999995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428571</th>\n",
       "      <td>2999998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  flag\n",
       "0             3     0\n",
       "1             8     0\n",
       "2             9     0\n",
       "3            13     0\n",
       "4            19     0\n",
       "...         ...   ...\n",
       "428567  2999986     0\n",
       "428568  2999988     0\n",
       "428569  2999989     0\n",
       "428570  2999995     0\n",
       "428571  2999998     0\n",
       "\n",
       "[428572 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv(\"/kaggle/input/alfa-bank-train-target-folds/val_target_fold_1.csv\")\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:42.409898Z",
     "iopub.status.busy": "2023-03-26T13:13:42.409108Z",
     "iopub.status.idle": "2023-03-26T13:13:42.650547Z",
     "shell.execute_reply": "2023-03-26T13:13:42.649140Z",
     "shell.execute_reply.started": "2023-03-26T13:13:42.409850Z"
    }
   },
   "outputs": [],
   "source": [
    "val.index = list(val['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:42.652460Z",
     "iopub.status.busy": "2023-03-26T13:13:42.652106Z",
     "iopub.status.idle": "2023-03-26T13:13:42.740300Z",
     "shell.execute_reply": "2023-03-26T13:13:42.739116Z",
     "shell.execute_reply.started": "2023-03-26T13:13:42.652427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999986</th>\n",
       "      <td>2999986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999988</th>\n",
       "      <td>2999988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999989</th>\n",
       "      <td>2999989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  flag\n",
       "3              3     0\n",
       "8              8     0\n",
       "9              9     0\n",
       "13            13     0\n",
       "19            19     0\n",
       "...          ...   ...\n",
       "2999986  2999986     0\n",
       "2999988  2999988     0\n",
       "2999989  2999989     0\n",
       "2999995  2999995     0\n",
       "2999998  2999998     0\n",
       "\n",
       "[428572 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:13:42.743080Z",
     "iopub.status.busy": "2023-03-26T13:13:42.742701Z",
     "iopub.status.idle": "2023-03-26T13:33:47.076596Z",
     "shell.execute_reply": "2023-03-26T13:33:47.075017Z",
     "shell.execute_reply.started": "2023-03-26T13:13:42.743043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c06ba5c86eb413da06efecaffaf44dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing credit data:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_0.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_1.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_2.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_3.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915ce2a806df4d1682a046634901d60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69ea1055dd4488ab383f25cb580a49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_4.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_5.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_6.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_7.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7768a1201f04e0caef1f8676aeefa56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe294a987adb4487b7b665f458ef7475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_8.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_9.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_10.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/train_data/train_data_11.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc18169aeb2e4ae5bd2bbf897a50d99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06ba06e928a4a06b6a9c7d5cc69b128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buckets_from_credits(TRAIN_DATA_PATH,\n",
    "                               bucket_info=bucket_info,\n",
    "                               save_to_path=TRAIN_BUCKETS_PATH_1,\n",
    "                               frame_with_ids=train,\n",
    "                               num_parts_to_preprocess_at_once=4,\n",
    "                               num_parts_total=12, has_target=True)\n",
    "\n",
    "dataset_train = sorted([os.path.join(TRAIN_BUCKETS_PATH_1, x) for x in \\\n",
    "                        os.listdir(TRAIN_BUCKETS_PATH_1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:33:47.078734Z",
     "iopub.status.busy": "2023-03-26T13:33:47.078338Z",
     "iopub.status.idle": "2023-03-26T13:33:47.165426Z",
     "shell.execute_reply": "2023-03-26T13:33:47.164523Z",
     "shell.execute_reply.started": "2023-03-26T13:33:47.078696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/.virtual_documents',\n",
       " '/kaggle/working/__notebook_source__.ipynb',\n",
       " '/kaggle/working/processed_chunk_000.pkl',\n",
       " '/kaggle/working/processed_chunk_001.pkl',\n",
       " '/kaggle/working/processed_chunk_002.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:41:05.067073Z",
     "iopub.status.busy": "2023-03-26T13:41:05.066607Z",
     "iopub.status.idle": "2023-03-26T13:44:28.712912Z",
     "shell.execute_reply": "2023-03-26T13:44:28.711463Z",
     "shell.execute_reply.started": "2023-03-26T13:41:05.067034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cc358979824ac99673d516088b7244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing credit data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/test_data/test_data_0.pq\n",
      "/kaggle/input/alfa-bank-pd-credit-history/data_for_competition/test_data/test_data_1.pq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047fc0dad5d84510b3cf4cb6e365e0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming credits to sequences is done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5417c38e1a4477980b21ba0ab496ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/test_buckets_rnn/processed_chunk_000.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_buckets_from_credits(TEST_DATA_PATH,\n",
    "                            bucket_info=bucket_info,\n",
    "                            save_to_path=TEST_BUCKETS_PATH, num_parts_to_preprocess_at_once=2,\n",
    "                            num_parts_total=2)\n",
    "\n",
    "dataset_test = sorted([os.path.join(TEST_BUCKETS_PATH, x) for x in os.listdir(TEST_BUCKETS_PATH)])\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-26T13:33:47.719375Z",
     "iopub.status.idle": "2023-03-26T13:33:47.719990Z",
     "shell.execute_reply": "2023-03-26T13:33:47.719701Z",
     "shell.execute_reply.started": "2023-03-26T13:33:47.719670Z"
    }
   },
   "outputs": [],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
